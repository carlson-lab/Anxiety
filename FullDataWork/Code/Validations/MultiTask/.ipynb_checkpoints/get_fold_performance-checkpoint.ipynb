{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c3c70-11bd-44c5-8e10-1f58606c8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from lpne.models import DcsfaNmf\n",
    "from lpne.plotting import circle_plot\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "umc_data_tools_path = \"/hpc/home/mk423/Anxiety/Universal-Mouse-Code/\"\n",
    "sys.path.append(umc_data_tools_path)\n",
    "import umc_data_tools as umc_dt\n",
    "\n",
    "N_COMPONENTS=30\n",
    "\n",
    "fold = 3#int(os.environ['SLURM_ARRAY_TASK_ID'])\n",
    "\n",
    "flx_data_path = \"/work/mk423/Anxiety/flx_kf_dict_fold_{}.pkl\".format(fold)\n",
    "epm_data_path = \"/work/mk423/Anxiety/epm_kf_dict_fold_{}.pkl\".format(fold)\n",
    "oft_data_path = \"/work/mk423/Anxiety/oft_kf_dict_fold_{}.pkl\".format(fold)\n",
    "anx_info_dict = \"/work/mk423/Anxiety/Anx_Info_Dict.pkl\"\n",
    "\n",
    "saved_model_path = \"/work/mk423/Anxiety/kfold_models/\"\n",
    "saved_model_name = \"2_sup_net_30_net_kf_fold_{}_model.pt\".format(fold)\n",
    "\n",
    "results_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Validations/\"\n",
    "results_file = results_path + \"2_sup_net_30_net_kf_fold_{}_results.pkl\".format(fold)\n",
    "\n",
    "projection_save_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Projections/\"\n",
    "plots_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Figures/\"\n",
    "\n",
    "\n",
    "def reshapeData(X_psd,X_coh,n_rois,n_freqs,pow_features,coh_features,areas):\n",
    "    X_3d = np.zeros((n_rois,n_rois,n_freqs))\n",
    "    \n",
    "    for i in range(n_rois):\n",
    "        X_3d[i,i,:] = X_psd[i*n_freqs:(i+1)*n_freqs]\n",
    "        \n",
    "    \n",
    "    split_coh_features = np.array([feature.split(' ')[0] for feature in coh_features])\n",
    "    #print(split_coh_features)\n",
    "    unique_coh_features = np.unique(split_coh_features)\n",
    "    for i in range(n_rois):\n",
    "        for j in range(n_rois):\n",
    "            if i != j:\n",
    "                area_1 = areas[i]\n",
    "                area_2 = areas[j]\n",
    "                temp_feature = area_1 + \"-\" + area_2\n",
    "                temp_feature_2 = area_2 + \"-\" + area_1\n",
    "                if temp_feature in unique_coh_features:\n",
    "                    feature_mask = np.where(split_coh_features==temp_feature,True,False)\n",
    "                    X_3d[i,j,:] = X_coh[feature_mask==1]\n",
    "                    X_3d[j,i,:] = X_coh[feature_mask==1]\n",
    "\n",
    "                elif temp_feature_2 in unique_coh_features:\n",
    "                    feature_mask = np.where(split_coh_features==temp_feature_2,1,0)\n",
    "                    X_3d[i,j,:] = X_coh[feature_mask==1]\n",
    "                    X_3d[j,i,:] = X_coh[feature_mask==1]\n",
    "\n",
    "                else:\n",
    "                    print(\"temp_feature: {} not found\".format(temp_feature))\n",
    "\n",
    "    return X_3d\n",
    "\n",
    "with open(flx_data_path,\"rb\") as f:\n",
    "    flx_dict = pickle.load(f)\n",
    "    \n",
    "with open(epm_data_path,\"rb\") as f:\n",
    "    epm_dict = pickle.load(f)\n",
    "    \n",
    "with open(oft_data_path,\"rb\") as f:\n",
    "    oft_dict = pickle.load(f)\n",
    "    \n",
    "with open(anx_info_dict,\"rb\") as f:\n",
    "    anxInfo = pickle.load(f)\n",
    "\n",
    "info_dict = anxInfo\n",
    "feature_groups = [(0,len(info_dict[\"powerFeatures\"])),\n",
    "                   (len(info_dict[\"powerFeatures\"]),len(info_dict[\"powerFeatures\"])+len(info_dict[\"cohFeatures\"])),\n",
    "                   (len(info_dict[\"powerFeatures\"])+len(info_dict[\"cohFeatures\"]),\n",
    "                    len(info_dict[\"powerFeatures\"])+len(info_dict[\"cohFeatures\"])+len(info_dict[\"gcFeatures\"]))]\n",
    "                   \n",
    "mt_X_train = np.vstack([flx_dict[\"X_train\"],epm_dict[\"X_train\"],oft_dict[\"X_train\"]])\n",
    "mt_y_train = np.hstack([flx_dict[\"y_train\"],epm_dict[\"y_train\"],oft_dict[\"y_train\"]]).reshape(-1,1)\n",
    "mt_y_train_2_net = np.hstack([mt_y_train,mt_y_train])\n",
    "mt_y_mouse_train = np.hstack([flx_dict[\"y_mouse_train\"],epm_dict[\"y_mouse_train\"],oft_dict[\"y_mouse_train\"]])\n",
    "mt_y_exp_train = np.hstack([np.ones(flx_dict[\"X_train\"].shape[0])*0,\n",
    "                           np.ones(epm_dict[\"X_train\"].shape[0]),\n",
    "                           np.ones(oft_dict[\"X_train\"].shape[0])*2])\n",
    "intercept_mask = OneHotEncoder().fit_transform(mt_y_mouse_train.reshape(-1,1)).todense()\n",
    "sample_groups = OrdinalEncoder().fit_transform(mt_y_mouse_train.reshape(-1,1))\n",
    "\n",
    "train_idxs = np.random.binomial(1,.7,size=mt_X_train.shape[0])\n",
    "val_idxs = 1 - train_idxs\n",
    "mt_X_val = np.vstack([flx_dict[\"X_val\"],epm_dict[\"X_val\"],oft_dict[\"X_val\"]])\n",
    "mt_y_val = np.hstack([flx_dict[\"y_val\"],epm_dict[\"y_val\"],oft_dict[\"y_val\"]]).reshape(-1,1)\n",
    "mt_y_val_2_net = np.hstack([mt_y_val,mt_y_val])\n",
    "mt_y_mouse_val = np.hstack([flx_dict[\"y_mouse_val\"],epm_dict[\"y_mouse_val\"],oft_dict[\"y_mouse_val\"]])\n",
    "\n",
    "TRAIN=False\n",
    "if TRAIN:\n",
    "    model = DcsfaNmf(\n",
    "        n_components=N_COMPONENTS,\n",
    "        n_intercepts=intercept_mask.shape[1],\n",
    "        n_sup_networks=2,\n",
    "        optim_name=\"SGD\",\n",
    "        recon_loss=\"MSE\",\n",
    "        sup_recon_type=\"Residual\",\n",
    "        sup_recon_weight=1,\n",
    "        feature_groups=feature_groups,\n",
    "        fixed_corr=[\"positive\",\"positive\"],\n",
    "        save_folder=saved_model_path,\n",
    "    )\n",
    "\n",
    "    model.fit(mt_X_train,\n",
    "              mt_y_train_2_net,\n",
    "              intercept_mask=intercept_mask,\n",
    "              y_sample_groups=mt_y_exp_train,\n",
    "              batch_size=128,\n",
    "              lr=1e-3,\n",
    "              n_pre_epochs=500,\n",
    "              n_epochs=1000,\n",
    "              nmf_max_iter=2000,\n",
    "              pretrain=True,\n",
    "              verbose=True,\n",
    "              X_val=mt_X_val,\n",
    "              y_val=mt_y_val_2_net,\n",
    "              best_model_name=saved_model_name)\n",
    "\n",
    "    torch.save(model,saved_model_path + saved_model_name)\n",
    "\n",
    "else:\n",
    "    torch.load(model,saved_model_path + saved_model_name)\n",
    "    \n",
    "#Multitask Performance\n",
    "mt_train_auc = model.score(mt_X_train,mt_y_train_2_net)\n",
    "mt_val_auc = model.score(mt_X_val,mt_y_val_2_net)\n",
    "\n",
    "#FLX Performance\n",
    "\n",
    "flx_y_train = np.hstack([flx_dict[\"y_train\"].reshape(-1,1),flx_dict[\"y_train\"].reshape(-1,1)])\n",
    "flx_y_val = np.hstack([flx_dict[\"y_val\"].reshape(-1,1),flx_dict[\"y_val\"].reshape(-1,1)])\n",
    "\n",
    "flx_train_auc = model.score(flx_dict[\"X_train\"],flx_y_train,\n",
    "                           flx_dict['y_mouse_train'],return_dict=True)\n",
    "flx_val_auc = model.score(flx_dict[\"X_val\"],flx_y_val,\n",
    "                          flx_dict[\"y_mouse_val\"],return_dict=True)\n",
    "\n",
    "#EPM Performance\n",
    "epm_y_train = np.hstack([epm_dict[\"y_train\"].reshape(-1,1),epm_dict[\"y_train\"].reshape(-1,1)])\n",
    "epm_y_val = np.hstack([epm_dict[\"y_val\"].reshape(-1,1),epm_dict[\"y_val\"].reshape(-1,1)])\n",
    "epm_train_auc = model.score(epm_dict[\"X_train\"],epm_y_train,\n",
    "                           epm_dict[\"y_mouse_train\"],return_dict=True)\n",
    "epm_val_auc = model.score(epm_dict[\"X_val\"],epm_y_val,\n",
    "                          epm_dict[\"y_mouse_val\"],return_dict=True)\n",
    "\n",
    "#OFT Performance\n",
    "oft_y_train = np.hstack([oft_dict[\"y_train\"].reshape(-1,1),oft_dict[\"y_train\"].reshape(-1,1)])\n",
    "oft_y_val = np.hstack([oft_dict[\"y_val\"].reshape(-1,1),oft_dict[\"y_val\"].reshape(-1,1)])\n",
    "\n",
    "oft_train_auc = model.score(oft_dict[\"X_train\"],oft_y_train,\n",
    "                            oft_dict['y_mouse_train'],return_dict=True)\n",
    "oft_val_auc = model.score(oft_dict[\"X_val\"],oft_y_val,\n",
    "                          oft_dict['y_mouse_val'],return_dict=True)\n",
    "\n",
    "print(\"\\nflx train\",flx_train_auc)\n",
    "print(\"\\nflx val\",flx_val_auc)\n",
    "print(\"\\nepm train\",epm_train_auc)\n",
    "print(\"\\nepm val\",epm_val_auc)\n",
    "print(\"\\noft train\",oft_train_auc)\n",
    "print(\"\\noft val\",oft_val_auc)\n",
    "\n",
    "s = model.project(mt_X_val)\n",
    "X_sup_recon = model.get_comp_recon(torch.Tensor(s).to(\"cuda\"),0)\n",
    "X_sup_recon_2 = model.get_comp_recon(torch.Tensor(s).to(\"cuda\"),1)\n",
    "X_recon = model.reconstruct(mt_X_val)\n",
    "\n",
    "net_1_recon_contribution = np.mean(X_sup_recon/X_recon,axis=0)\n",
    "net_2_recon_contribution = np.mean(X_sup_recon_2/X_recon,axis=0)\n",
    "\n",
    "rec_psd = net_1_recon_contribution[:len(anxInfo[\"powerFeatures\"])]\n",
    "rec_coh = net_1_recon_contribution[len(anxInfo[\"powerFeatures\"]):(len(anxInfo[\"powerFeatures\"]) + len(anxInfo[\"cohFeatures\"]))]\n",
    "rec_3d = reshapeData(rec_psd,rec_coh,8,56,anxInfo[\"powerFeatures\"],anxInfo[\"cohFeatures\"],anxInfo[\"area\"])\n",
    "\n",
    "rec_psd_2 = net_2_recon_contribution[:len(anxInfo[\"powerFeatures\"])]\n",
    "rec_coh_2 = net_2_recon_contribution[len(anxInfo[\"powerFeatures\"]):(len(anxInfo[\"powerFeatures\"]) + len(anxInfo[\"cohFeatures\"]))]\n",
    "rec_3d_2 = reshapeData(rec_psd_2,rec_coh_2,8,56,anxInfo[\"powerFeatures\"],anxInfo[\"cohFeatures\"],anxInfo[\"area\"])\n",
    "\n",
    "circle_plot(rec_3d,anxInfo[\"area\"],freqs=np.arange(56),freq_ticks=np.arange(0,56,5),\n",
    "            min_max_quantiles=(0.85,0.9999),fn=plots_path + \"net_1_30_component_kf_fold_{}_electome.png\".format(fold))\n",
    "\n",
    "circle_plot(rec_3d_2,anxInfo[\"area\"],freqs=np.arange(56),freq_ticks=np.arange(0,56,5),\n",
    "            min_max_quantiles=(0.85,0.9999),fn=plots_path + \"net_2_30_component_kf_fold_{}_electome.png\".format(fold))\n",
    "\n",
    "umc_dt.makeUpperTriangularPlot_pow_coh_gc(net_1_recon_contribution.reshape(1,-1),anxInfo[\"area\"],anxInfo[\"powerFeatures\"],\n",
    "                                          anxInfo[\"cohFeatures\"],anxInfo[\"gcFeatures\"],\n",
    "                                          saveFile=plots_path + \"net_1_30_component_kf_fold_{}_up-tri.png\".format(fold))\n",
    "umc_dt.makeUpperTriangularPlot_pow_coh_gc(net_2_recon_contribution.reshape(1,-1),anxInfo[\"area\"],anxInfo[\"powerFeatures\"],\n",
    "                                          anxInfo[\"cohFeatures\"],anxInfo[\"gcFeatures\"],\n",
    "                                          saveFile=plots_path + \"net_2_30_component_kf_fold_{}_up-tri.png\".format(fold))\n",
    "\n",
    "results_dict = {\n",
    "    \"flx_train_auc\":flx_train_auc,\n",
    "    \"flx_val_auc\":flx_val_auc,\n",
    "    \"epm_train_auc\":epm_train_auc,\n",
    "    \"epm_val_auc\":epm_val_auc,\n",
    "    \"oft_train_auc\":oft_train_auc,\n",
    "    \"oft_val_auc\":oft_val_auc,\n",
    "    \"recon_cont_net_1\":net_1_recon_contribution,\n",
    "    \"recon_cont_net_2\":net_2_recon_contribution,\n",
    "    \"best_epoch\":model.best_epoch,\n",
    "}\n",
    "\n",
    "with open(results_file,\"wb\") as f:\n",
    "    pickle.dump(results_dict,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
