{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec19b6c-a0fe-4a04-8609-ea3c45ad5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from lpne.models import DcsfaNmf\n",
    "from lpne.plotting import circle_plot\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "TRAIN_TASK = \"flx\"\n",
    "network_array = np.arange(3,61,3)\n",
    "array_id = 1 #int(os.environ['SLURM_ARRAY_TASK_ID'])\n",
    "N_COMPONENTS = network_array[array_id]\n",
    "\n",
    "flx_data_path = \"/work/mk423/Anxiety/final_FLX_{}.pkl\"\n",
    "epm_data_path = \"/work/mk423/Anxiety/EPM_{}_dict_May_17.pkl\"\n",
    "oft_data_path = \"/work/mk423/Anxiety/OFT_{}_dict_old_features_hand_picked.pkl\"\n",
    "\n",
    "anx_info_dict = \"/work/mk423/Anxiety/Anx_Info_Dict.pkl\"\n",
    "\n",
    "saved_model_path = \"/work/mk423/Anxiety/single_task_models/n_net_models\"\n",
    "saved_model_name = \"{}_{}_net_cv_anx.pt\".format(TRAIN_TASK,N_COMPONENTS)\n",
    "\n",
    "projection_save_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Projections/\"\n",
    "plots_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Figures/SingleTask/\"\n",
    "\n",
    "results_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Validations/SingleTask/\"\n",
    "results_file = results_path + \"{}_{}_net_val_results.pkl\".format(TRAIN_TASK,N_COMPONENTS)\n",
    "\n",
    "feature_list = [\"X_psd\",\"X_coh\",\"X_gc\"]\n",
    "old_feature_list = [\"X_power_1_2\",\"X_coh_1_2\",\"X_gc_1_2\"]\n",
    "feature_weights = [10,1,1]\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "with open(flx_data_path.format(\"train\"),\"rb\") as f:\n",
    "    train_dict = pickle.load(f)\n",
    "    \n",
    "with open(flx_data_path.format(\"val\"),\"rb\") as f:\n",
    "    val_dict = pickle.load(f)\n",
    "    \n",
    "with open(flx_data_path.format(\"test\"),\"rb\") as f:\n",
    "    test_dict = pickle.load(f)\n",
    "    \n",
    "flx_X_train = np.hstack([train_dict[feature]*weight for feature,weight in zip(feature_list,feature_weights)])\n",
    "flx_y_train = train_dict['y_flx']\n",
    "flx_y_mouse_train = train_dict['y_mouse']\n",
    "flx_y_hab_train = train_dict['y_hab']\n",
    "flx_y_time_train = train_dict['y_time']\n",
    "\n",
    "flx_X_val = np.hstack([val_dict[feature]*weight for feature,weight in zip(feature_list,feature_weights)])\n",
    "flx_y_val = val_dict['y_flx']\n",
    "flx_y_mouse_val = val_dict['y_mouse']\n",
    "flx_y_hab_val = val_dict['y_hab']\n",
    "flx_y_time_val = val_dict['y_time']\n",
    "\n",
    "flx_X_test = np.hstack([test_dict[feature]*weight for feature,weight in zip(feature_list,feature_weights)])\n",
    "flx_y_test = test_dict['y_flx']\n",
    "flx_y_mouse_test = test_dict['y_mouse']\n",
    "flx_y_hab_test = test_dict['y_hab']\n",
    "flx_y_time_test = test_dict['y_time']\n",
    "\n",
    "flx_X = np.vstack([flx_X_train[flx_y_hab_train==1],flx_X_val[flx_y_hab_val==1]])\n",
    "flx_y = np.hstack([flx_y_train[flx_y_hab_train==1],flx_y_val[flx_y_hab_val==1]])\n",
    "flx_y_mouse = np.hstack([flx_y_mouse_train[flx_y_hab_train==1],flx_y_mouse_val[flx_y_hab_val==1]])\n",
    "\n",
    "\n",
    "with open(oft_data_path.format(\"train\"),'rb') as f:\n",
    "    train_dict = pickle.load(f)\n",
    "\n",
    "with open(oft_data_path.format(\"validation\"),'rb') as f:\n",
    "    val_dict = pickle.load(f)\n",
    "    \n",
    "with open(oft_data_path.format(\"test\"),'rb') as f:\n",
    "    test_dict = pickle.load(f)\n",
    "    \n",
    "\n",
    "running_idx = 0\n",
    "feature_groups = []\n",
    "for idx,feature in enumerate(old_feature_list):\n",
    "    f_begin = running_idx\n",
    "    f_end = f_begin + train_dict[feature].shape[1] \n",
    "    if idx == 0:\n",
    "        f_end = f_end -1\n",
    "    feature_groups.append((f_begin,f_end))\n",
    "\n",
    "    running_idx = f_end\n",
    "\n",
    "NUM_FREQS = 56\n",
    "NUM_FEATURES = np.hstack([train_dict[feature] for feature in old_feature_list]).shape[1] // NUM_FREQS\n",
    "scale_vector = np.array([np.arange(1,NUM_FREQS+1) for feature in range(NUM_FEATURES)]).flatten()\n",
    "\n",
    "#Train Arrays\n",
    "oft_X_train = np.hstack([train_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "oft_y_hc_train = train_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_train = ~oft_y_hc_train\n",
    "oft_y_ROI_train = train_dict['y_ROI']\n",
    "oft_y_vel_train = train_dict['y_vel']\n",
    "oft_y_mouse_train = train_dict['y_mouse']\n",
    "oft_y_time_train = train_dict['y_time']\n",
    "\n",
    "#Validation Arrays\n",
    "oft_X_val = np.hstack([val_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "oft_y_hc_val = val_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_val = ~oft_y_hc_val\n",
    "oft_y_ROI_val = val_dict['y_ROI']\n",
    "oft_y_vel_val = val_dict['y_vel']\n",
    "oft_y_mouse_val = val_dict['y_mouse']\n",
    "oft_y_time_val = val_dict['y_time']\n",
    "\n",
    "#Test Arrays\n",
    "oft_X_test = np.hstack([test_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "oft_y_hc_test = test_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_test = ~oft_y_hc_test\n",
    "oft_y_ROI_test = test_dict['y_ROI']\n",
    "oft_y_vel_test = test_dict['y_vel']\n",
    "oft_y_mouse_test = test_dict['y_mouse']\n",
    "oft_y_time_test = test_dict['y_time']\n",
    "\n",
    "oft_X = np.vstack([oft_X_train,oft_X_val])\n",
    "oft_y_task = np.hstack([oft_y_task_train,oft_y_task_val])\n",
    "oft_y_mouse = np.hstack([oft_y_mouse_train,oft_y_mouse_val])\n",
    "\n",
    "with open(epm_data_path.format(\"train\"),\"rb\") as f:\n",
    "    epm_train_dict = pickle.load(f)\n",
    "\n",
    "with open(epm_data_path.format(\"val\"),\"rb\") as f:\n",
    "    epm_validation_dict = pickle.load(f)\n",
    "    \n",
    "with open(epm_data_path.format(\"test\"),\"rb\") as f:\n",
    "    epm_test_dict = pickle.load(f)\n",
    "\n",
    "#Load the data\n",
    "NUM_FREQS = 56\n",
    "NUM_FEATURES = (epm_train_dict[\"X_power_1_2\"].shape[1] + \\\n",
    "                epm_train_dict[\"X_coh_1_2\"].shape[1] + \\\n",
    "                epm_train_dict[\"X_gc_1_2\"].shape[1]) // NUM_FREQS\n",
    "SCALE_VECTOR = np.array([np.arange(1,57) for feature in range(NUM_FEATURES)]).flatten()\n",
    "\n",
    "X_train = np.hstack([epm_train_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "X_train[X_train<0] = 0\n",
    "y_train = (epm_train_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_train = ~epm_train_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_train = epm_train_dict['y_mouse']\n",
    "y_time_train = epm_train_dict['y_time']\n",
    "train_nan_mask = (epm_train_dict['y_ROI'] > 0)\n",
    "\n",
    "\n",
    "X_train_task = X_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_train_task = y_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_mouse_train_task = y_mouse_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_time_train_task = y_time_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "\n",
    "\n",
    "X_val = np.hstack([epm_validation_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "y_val = (epm_validation_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_val= ~epm_validation_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_val = epm_validation_dict['y_mouse']\n",
    "y_time_val = epm_validation_dict['y_time']\n",
    "val_nan_mask = (epm_validation_dict['y_ROI'] > 0)\n",
    "\n",
    "X_val_task = X_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_val_task = y_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_mouse_val_task = y_mouse_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_time_val_task = y_time_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "\n",
    "X_test = np.hstack([epm_test_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "y_test = (epm_test_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_test= ~epm_test_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_test = epm_test_dict['y_mouse']\n",
    "y_time_test = epm_test_dict['y_time']\n",
    "test_nan_mask = (epm_test_dict['y_ROI'] > 0)\n",
    "\n",
    "X_test_task = X_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_test_task = y_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_mouse_test_task = y_mouse_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_time_test_task = y_time_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "\n",
    "epm_X = np.vstack([X_train,X_val])\n",
    "epm_y_task = np.hstack([y_in_task_mask_train,y_in_task_mask_val])\n",
    "epm_y_mouse = np.hstack([y_mouse_train,y_mouse_val])\n",
    "epm_y_time = np.hstack([y_time_train,y_time_val])\n",
    "\n",
    "\n",
    "intercept_mask = OneHotEncoder().fit_transform(flx_y_mouse_train[flx_y_hab_train==1].reshape(-1,1)).todense()\n",
    "sample_groups = OrdinalEncoder().fit_transform(flx_y_mouse_train[flx_y_hab_train==1].reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d0c81e-8cfb-4890-95e9-324e17a694f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25489, 5152)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flx_X_train[flx_y_hab_train==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175b0c6-10ef-43dd-bb21-0711cf9dd75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flx_y_train[flx_y_hab_train==1].reshape(-1,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
