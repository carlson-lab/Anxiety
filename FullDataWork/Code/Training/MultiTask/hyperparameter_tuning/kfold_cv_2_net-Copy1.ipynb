{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338b78d0-9e2a-4226-8328-e2c3fcd6afaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/hpc/home/mk423/.local/lib/python3.7/site-packages/lpne/pipelines/__init__.py:14: UserWarning: Could not load lpne/pipelines/default_params.yaml!\n",
      "  warnings.warn(\"Could not load lpne/pipelines/default_params.yaml!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining NMF...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1033213/3637898700.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    125\u001b[0m           \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmt_X_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m           \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmt_y_val_2_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m           best_model_name=saved_model_name)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;31m#Multitask Performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lpne/models/dcsfa_nmf.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, y_pred_weights, task_mask, intercept_mask, y_sample_groups, n_epochs, n_pre_epochs, nmf_max_iter, batch_size, lr, pretrain, verbose, X_val, y_val, y_pred_weights_val, task_mask_val, best_model_name)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# Pretrain the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpretrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrain_NMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmf_max_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m             self.pretrain_encoder(\n\u001b[1;32m    640\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lpne/models/nmf_base.py\u001b[0m in \u001b[0;36mpretrain_NMF\u001b[0;34m(self, X, y, nmf_max_iter)\u001b[0m\n\u001b[1;32m    223\u001b[0m             )\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0ms_NMF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNMF_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;31m# define arrays for storing model predictive information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mselected_networks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, W, H)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massume_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m             \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m         self.reconstruction_err_ = _beta_divergence(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, W, H, update_H)\u001b[0m\n\u001b[1;32m   1614\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1616\u001b[0;31m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1617\u001b[0m             )\n\u001b[1;32m   1618\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36m_fit_coordinate_descent\u001b[0;34m(X, W, H, tol, max_iter, l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H, update_H, verbose, shuffle, random_state)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupdate_H\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             violation += _update_coordinate_descent(\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             )\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36m_update_coordinate_descent\u001b[0;34m(X, W, Ht, l1_reg, l2_reg, shuffle, random_state)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mHHt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mXHt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;31m# L2 regularization corresponds to increase of the diagonal of HHt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from lpne.models import DcsfaNmf\n",
    "from lpne.plotting import circle_plot\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "umc_data_tools_path = \"/hpc/home/mk423/Anxiety/Universal-Mouse-Code/\"\n",
    "sys.path.append(umc_data_tools_path)\n",
    "import umc_data_tools as umc_dt\n",
    "\n",
    "N_COMPONENTS=30\n",
    "\n",
    "fold = 5#int(os.environ['SLURM_ARRAY_TASK_ID'])\n",
    "\n",
    "flx_data_path = \"/work/mk423/Anxiety/flx_kf_dict_fold_{}.pkl\".format(fold)\n",
    "epm_data_path = \"/work/mk423/Anxiety/epm_kf_dict_fold_{}.pkl\".format(fold)\n",
    "oft_data_path = \"/work/mk423/Anxiety/oft_kf_dict_fold_{}.pkl\".format(fold)\n",
    "anx_info_dict = \"/work/mk423/Anxiety/Anx_Info_Dict.pkl\"\n",
    "\n",
    "saved_model_path = \"/work/mk423/Anxiety/kfold_models/\"\n",
    "saved_model_name = \"2_sup_net_30_net_kf_fold_{}_model.pt\".format(fold)\n",
    "\n",
    "results_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Validations/\"\n",
    "results_file = results_path + \"2_sup_net_30_net_kf_fold_{}_results.pkl\".format(fold)\n",
    "\n",
    "projection_save_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Projections/\"\n",
    "plots_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Figures/\"\n",
    "\n",
    "\n",
    "def reshapeData(X_psd,X_coh,n_rois,n_freqs,pow_features,coh_features,areas):\n",
    "    X_3d = np.zeros((n_rois,n_rois,n_freqs))\n",
    "    \n",
    "    for i in range(n_rois):\n",
    "        X_3d[i,i,:] = X_psd[i*n_freqs:(i+1)*n_freqs]\n",
    "        \n",
    "    \n",
    "    split_coh_features = np.array([feature.split(' ')[0] for feature in coh_features])\n",
    "    #print(split_coh_features)\n",
    "    unique_coh_features = np.unique(split_coh_features)\n",
    "    for i in range(n_rois):\n",
    "        for j in range(n_rois):\n",
    "            if i != j:\n",
    "                area_1 = areas[i]\n",
    "                area_2 = areas[j]\n",
    "                temp_feature = area_1 + \"-\" + area_2\n",
    "                temp_feature_2 = area_2 + \"-\" + area_1\n",
    "                if temp_feature in unique_coh_features:\n",
    "                    feature_mask = np.where(split_coh_features==temp_feature,True,False)\n",
    "                    X_3d[i,j,:] = X_coh[feature_mask==1]\n",
    "                    X_3d[j,i,:] = X_coh[feature_mask==1]\n",
    "\n",
    "                elif temp_feature_2 in unique_coh_features:\n",
    "                    feature_mask = np.where(split_coh_features==temp_feature_2,1,0)\n",
    "                    X_3d[i,j,:] = X_coh[feature_mask==1]\n",
    "                    X_3d[j,i,:] = X_coh[feature_mask==1]\n",
    "\n",
    "                else:\n",
    "                    print(\"temp_feature: {} not found\".format(temp_feature))\n",
    "\n",
    "    return X_3d\n",
    "\n",
    "with open(flx_data_path,\"rb\") as f:\n",
    "    flx_dict = pickle.load(f)\n",
    "    \n",
    "with open(epm_data_path,\"rb\") as f:\n",
    "    epm_dict = pickle.load(f)\n",
    "    \n",
    "with open(oft_data_path,\"rb\") as f:\n",
    "    oft_dict = pickle.load(f)\n",
    "    \n",
    "with open(anx_info_dict,\"rb\") as f:\n",
    "    anxInfo = pickle.load(f)\n",
    "\n",
    "info_dict = anxInfo\n",
    "feature_groups = [(0,len(info_dict[\"powerFeatures\"])),\n",
    "                   (len(info_dict[\"powerFeatures\"]),len(info_dict[\"powerFeatures\"])+len(info_dict[\"cohFeatures\"])),\n",
    "                   (len(info_dict[\"powerFeatures\"])+len(info_dict[\"cohFeatures\"]),\n",
    "                    len(info_dict[\"powerFeatures\"])+len(info_dict[\"cohFeatures\"])+len(info_dict[\"gcFeatures\"]))]\n",
    "                   \n",
    "mt_X_train = np.vstack([flx_dict[\"X_train\"],epm_dict[\"X_train\"],oft_dict[\"X_train\"]])\n",
    "mt_y_train = np.hstack([flx_dict[\"y_train\"],epm_dict[\"y_train\"],oft_dict[\"y_train\"]]).reshape(-1,1)\n",
    "mt_y_train_2_net = np.hstack([mt_y_train,mt_y_train])\n",
    "mt_y_mouse_train = np.hstack([flx_dict[\"y_mouse_train\"],epm_dict[\"y_mouse_train\"],oft_dict[\"y_mouse_train\"]])\n",
    "mt_y_exp_train = np.hstack([np.ones(flx_dict[\"X_train\"].shape[0])*0,\n",
    "                           np.ones(epm_dict[\"X_train\"].shape[0]),\n",
    "                           np.ones(oft_dict[\"X_train\"].shape[0])*2])\n",
    "intercept_mask = OneHotEncoder().fit_transform(mt_y_mouse_train.reshape(-1,1)).todense()\n",
    "sample_groups = OrdinalEncoder().fit_transform(mt_y_mouse_train.reshape(-1,1))\n",
    "\n",
    "train_idxs = np.random.binomial(1,.7,size=mt_X_train.shape[0])\n",
    "val_idxs = 1 - train_idxs\n",
    "mt_X_val = np.vstack([flx_dict[\"X_val\"],epm_dict[\"X_val\"],oft_dict[\"X_val\"]])\n",
    "mt_y_val = np.hstack([flx_dict[\"y_val\"],epm_dict[\"y_val\"],oft_dict[\"y_val\"]]).reshape(-1,1)\n",
    "mt_y_val_2_net = np.hstack([mt_y_val,mt_y_val])\n",
    "mt_y_mouse_val = np.hstack([flx_dict[\"y_mouse_val\"],epm_dict[\"y_mouse_val\"],oft_dict[\"y_mouse_val\"]])\n",
    "\n",
    "model = DcsfaNmf(\n",
    "    n_components=N_COMPONENTS,\n",
    "    n_intercepts=intercept_mask.shape[1],\n",
    "    n_sup_networks=2,\n",
    "    optim_name=\"SGD\",\n",
    "    recon_loss=\"MSE\",\n",
    "    sup_recon_type=\"Residual\",\n",
    "    sup_recon_weight=1,\n",
    "    feature_groups=feature_groups,\n",
    "    fixed_corr=[\"positive\",\"positive\"],\n",
    "    save_folder=saved_model_path,\n",
    ")\n",
    "\n",
    "model.fit(mt_X_train,\n",
    "          mt_y_train_2_net,\n",
    "          intercept_mask=intercept_mask,\n",
    "          y_sample_groups=mt_y_exp_train,\n",
    "          batch_size=128,\n",
    "          lr=1e-3,\n",
    "          n_pre_epochs=500,\n",
    "          n_epochs=1000,\n",
    "          nmf_max_iter=2000,\n",
    "          pretrain=True,\n",
    "          verbose=True,\n",
    "          X_val=mt_X_val,\n",
    "          y_val=mt_y_val_2_net,\n",
    "          best_model_name=saved_model_name)\n",
    "\n",
    "#Multitask Performance\n",
    "mt_train_auc = model.score(mt_X_train,mt_y_train_2_net)\n",
    "mt_val_auc = model.score(mt_X_val,mt_y_val_2_net)\n",
    "\n",
    "#FLX Performance\n",
    "\n",
    "flx_y_train = np.hstack([flx_dict[\"y_train\"].reshape(-1,1),flx_dict[\"y_train\"].reshape(-1,1)])\n",
    "flx_y_val = np.hstack([flx_dict[\"y_val\"].reshape(-1,1),flx_dict[\"y_val\"].reshape(-1,1)])\n",
    "\n",
    "flx_train_auc = model.score(flx_dict[\"X_train\"],flx_y_train,\n",
    "                           flx_dict['y_mouse_train'],return_dict=True)\n",
    "flx_val_auc = model.score(flx_dict[\"X_val\"],flx_y_val,\n",
    "                          flx_dict[\"y_mouse_val\"],return_dict=True)\n",
    "\n",
    "#EPM Performance\n",
    "epm_y_train = np.hstack([epm_dict[\"y_train\"].reshape(-1,1),epm_dict[\"y_train\"].reshape(-1,1)])\n",
    "epm_y_val = np.hstack([epm_dict[\"y_val\"].reshape(-1,1),epm_dict[\"y_val\"].reshape(-1,1)])\n",
    "epm_train_auc = model.score(epm_dict[\"X_train\"],epm_y_train,\n",
    "                           epm_dict[\"y_mouse_train\"],return_dict=True)\n",
    "epm_val_auc = model.score(epm_dict[\"X_val\"],epm_y_val,\n",
    "                          epm_dict[\"y_mouse_val\"],return_dict=True)\n",
    "\n",
    "#OFT Performance\n",
    "oft_y_train = np.hstack([oft_dict[\"y_train\"].reshape(-1,1),oft_dict[\"y_train\"].reshape(-1,1)])\n",
    "oft_y_val = np.hstack([oft_dict[\"y_val\"].reshape(-1,1),oft_dict[\"y_val\"].reshape(-1,1)])\n",
    "\n",
    "oft_train_auc = model.score(oft_dict[\"X_train\"],oft_y_train,\n",
    "                            oft_dict['y_mouse_train'],return_dict=True)\n",
    "oft_val_auc = model.score(oft_dict[\"X_val\"],oft_y_val,\n",
    "                          oft_dict['y_mouse_val'],return_dict=True)\n",
    "\n",
    "print(\"\\nflx train\",flx_train_auc)\n",
    "print(\"\\nflx val\",flx_val_auc)\n",
    "print(\"\\nepm train\",epm_train_auc)\n",
    "print(\"\\nepm val\",epm_val_auc)\n",
    "print(\"\\noft train\",oft_train_auc)\n",
    "print(\"\\noft val\",oft_val_auc)\n",
    "\n",
    "s = model.project(mt_X_val)\n",
    "X_sup_recon = model.get_comp_recon(torch.Tensor(s).to(\"cuda\"),0)\n",
    "X_sup_recon_2 = model.get_comp_recon(torch.Tensor(s).to(\"cuda\"),1)\n",
    "X_recon = model.reconstruct(mt_X_val)\n",
    "\n",
    "net_1_recon_contribution = np.mean(X_sup_recon/X_recon,axis=0)\n",
    "net_2_recon_contribution = np.mean(X_sup_recon_2/X_recon,axis=0)\n",
    "\n",
    "rec_psd = net_1_recon_contribution[:len(anxInfo[\"powerFeatures\"])]\n",
    "rec_coh = net_1_recon_contribution[len(anxInfo[\"powerFeatures\"]):(len(anxInfo[\"powerFeatures\"]) + len(anxInfo[\"cohFeatures\"]))]\n",
    "rec_3d = reshapeData(rec_psd,rec_coh,8,56,anxInfo[\"powerFeatures\"],anxInfo[\"cohFeatures\"],anxInfo[\"area\"])\n",
    "\n",
    "rec_psd_2 = net_2_recon_contribution[:len(anxInfo[\"powerFeatures\"])]\n",
    "rec_coh_2 = net_2_recon_contribution[len(anxInfo[\"powerFeatures\"]):(len(anxInfo[\"powerFeatures\"]) + len(anxInfo[\"cohFeatures\"]))]\n",
    "rec_3d_2 = reshapeData(rec_psd_2,rec_coh_2,8,56,anxInfo[\"powerFeatures\"],anxInfo[\"cohFeatures\"],anxInfo[\"area\"])\n",
    "\n",
    "circle_plot(rec_3d,anxInfo[\"area\"],freqs=np.arange(56),freq_ticks=np.arange(0,56,5),\n",
    "            min_max_quantiles=(0.85,0.9999),fn=plots_path + \"net_1_30_component_kf_fold_{}_electome.png\".format(fold))\n",
    "\n",
    "circle_plot(rec_3d_2,anxInfo[\"area\"],freqs=np.arange(56),freq_ticks=np.arange(0,56,5),\n",
    "            min_max_quantiles=(0.85,0.9999),fn=plots_path + \"net_2_30_component_kf_fold_{}_electome.png\".format(fold))\n",
    "\n",
    "umc_dt.makeUpperTriangularPlot_pow_coh_gc(net_1_recon_contribution.reshape(1,-1),anxInfo[\"area\"],anxInfo[\"powerFeatures\"],\n",
    "                                          anxInfo[\"cohFeatures\"],anxInfo[\"gcFeatures\"],\n",
    "                                          saveFile=plots_path + \"net_1_30_component_kf_fold_{}_up-tri.png\".format(fold))\n",
    "umc_dt.makeUpperTriangularPlot_pow_coh_gc(net_2_recon_contribution.reshape(1,-1),anxInfo[\"area\"],anxInfo[\"powerFeatures\"],\n",
    "                                          anxInfo[\"cohFeatures\"],anxInfo[\"gcFeatures\"],\n",
    "                                          saveFile=plots_path + \"net_2_30_component_kf_fold_{}_up-tri.png\".format(fold))\n",
    "\n",
    "results_dict = {\n",
    "    \"flx_train_auc\":flx_train_auc,\n",
    "    \"flx_val_auc\":flx_val_auc,\n",
    "    \"epm_train_auc\":epm_train_auc,\n",
    "    \"epm_val_auc\":epm_val_auc,\n",
    "    \"oft_train_auc\":oft_train_auc,\n",
    "    \"oft_val_auc\":oft_val_auc,\n",
    "    \"recon_cont_net_1\":net_1_recon_contribution,\n",
    "    \"recon_cont_net_2\":net_2_recon_contribution,\n",
    "    \"best_epoch\":model.best_epoch,\n",
    "}\n",
    "\n",
    "with open(results_file,\"wb\") as f:\n",
    "    pickle.dump(results_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25218b4c-a657-418b-b661-aba6f80f8fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
