{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531834d8-7019-4349-846d-0ae5a709e044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/hpc/home/mk423/.local/lib/python3.7/site-packages/lpne/pipelines/__init__.py:14: UserWarning: Could not load lpne/pipelines/default_params.yaml!\n",
      "  warnings.warn(\"Could not load lpne/pipelines/default_params.yaml!\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from lpne.models import DcsfaNmf\n",
    "from lpne.plotting import circle_plot\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "#from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "import os, sys\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "umc_data_tools_path = \"/hpc/home/mk423/Anxiety/Universal-Mouse-Code/\"\n",
    "sys.path.append(umc_data_tools_path)\n",
    "import umc_data_tools as umc_dt\n",
    "\n",
    "featureIdx = 5#int(os.environ['SLURM_ARRAY_TASK_ID']) #0-91\n",
    "\n",
    "flx_data_path = \"/work/mk423/Anxiety/final_FLX_{}.pkl\"\n",
    "epm_data_path = \"/work/mk423/Anxiety/EPM_{}_dict_May_17.pkl\"\n",
    "oft_data_path = \"/work/mk423/Anxiety/OFT_{}_dict_old_features_hand_picked.pkl\"\n",
    "\n",
    "anx_info_dict = \"/work/mk423/Anxiety/Anx_Info_Dict.pkl\"\n",
    "\n",
    "feature_list = [\"X_psd\",\"X_coh\",\"X_gc\"]\n",
    "old_feature_list = [\"X_power_1_2\",\"X_coh_1_2\",\"X_gc_1_2\"]\n",
    "feature_weights = [10,1,1]\n",
    "RANDOM_STATE = 42\n",
    "EPSILON = 1e-6\n",
    "anxInfoDict = pickle.load(open(anx_info_dict,\"rb\"))\n",
    "allFeatures = np.hstack([anxInfoDict[\"powerFeatures\"],anxInfoDict[\"cohFeatures\"],anxInfoDict[\"gcFeatures\"]])\n",
    "\n",
    "currentFeature = np.unique([feature.split(\" \")[0] for feature in allFeatures[56*featureIdx:56*(featureIdx+1)]])[0]\n",
    "\n",
    "saved_model_path = \"/work/mk423/Anxiety/MultiTask/singleFeatureModels/\"\n",
    "saved_model_name = \"{}_singleFeature_model_{}_components.pt\"\n",
    "\n",
    "results_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Validations/\"\n",
    "results_file = results_path + \"{}_singleFeature_model_{}_components_results.pkl\"\n",
    "\n",
    "projection_save_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Projections/\"\n",
    "plots_path = \"/hpc/home/mk423/Anxiety/FullDataWork/Figures/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ecd41d-e95c-4338-abb5-3e8d5e7476a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(flx_data_path.format(\"train\"),\"rb\") as f:\n",
    "    train_dict = pickle.load(f)\n",
    "    \n",
    "with open(flx_data_path.format(\"val\"),\"rb\") as f:\n",
    "    val_dict = pickle.load(f)\n",
    "    \n",
    "with open(flx_data_path.format(\"test\"),\"rb\") as f:\n",
    "    test_dict = pickle.load(f)\n",
    "    \n",
    "flx_X_train = np.hstack([train_dict[feature]*weight for feature,weight in zip(feature_list,feature_weights)])\n",
    "flx_y_train = train_dict['y_flx']\n",
    "flx_y_mouse_train = train_dict['y_mouse']\n",
    "flx_y_hab_train = train_dict['y_hab']\n",
    "flx_y_time_train = train_dict['y_time']\n",
    "\n",
    "flx_X_val = np.hstack([val_dict[feature]*weight for feature,weight in zip(feature_list,feature_weights)])\n",
    "flx_y_val = val_dict['y_flx']\n",
    "flx_y_mouse_val = val_dict['y_mouse']\n",
    "flx_y_hab_val = val_dict['y_hab']\n",
    "flx_y_time_val = val_dict['y_time']\n",
    "\n",
    "flx_X_test = np.hstack([test_dict[feature]*weight for feature,weight in zip(feature_list,feature_weights)])\n",
    "flx_y_test = test_dict['y_flx']\n",
    "flx_y_mouse_test = test_dict['y_mouse']\n",
    "flx_y_hab_test = test_dict['y_hab']\n",
    "flx_y_time_test = test_dict['y_time']\n",
    "flx_y_expDate_test = test_dict['y_expDate']\n",
    "\n",
    "#Stack Validation and Training Data from timepoints after 30 minutes\n",
    "flx_X = np.vstack([flx_X_train[flx_y_hab_train==1],flx_X_val[flx_y_hab_val==1]])\n",
    "flx_y = np.hstack([flx_y_train[flx_y_hab_train==1],flx_y_val[flx_y_hab_val==1]])\n",
    "flx_y_mouse = np.hstack([flx_y_mouse_train[flx_y_hab_train==1], flx_y_mouse_val[flx_y_hab_val==1]])\n",
    "\n",
    "with open(oft_data_path.format(\"train\"),'rb') as f:\n",
    "    train_dict = pickle.load(f)\n",
    "\n",
    "with open(oft_data_path.format(\"validation\"),'rb') as f:\n",
    "    val_dict = pickle.load(f)\n",
    "    \n",
    "with open(oft_data_path.format(\"test\"),'rb') as f:\n",
    "    test_dict = pickle.load(f)\n",
    "    \n",
    "\n",
    "running_idx = 0\n",
    "feature_groups = []\n",
    "for idx,feature in enumerate(old_feature_list):\n",
    "    f_begin = running_idx\n",
    "    f_end = f_begin + train_dict[feature].shape[1] \n",
    "    if idx == 0:\n",
    "        f_end = f_end -1\n",
    "    feature_groups.append((f_begin,f_end))\n",
    "\n",
    "    running_idx = f_end\n",
    "\n",
    "NUM_FREQS = 56\n",
    "NUM_FEATURES = np.hstack([train_dict[feature] for feature in old_feature_list]).shape[1] // NUM_FREQS\n",
    "scale_vector = np.array([np.arange(1,NUM_FREQS+1) for feature in range(NUM_FEATURES)]).flatten()\n",
    "\n",
    "#Train Arrays\n",
    "oft_X_train = np.hstack([train_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "oft_y_hc_train = train_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_train = ~oft_y_hc_train\n",
    "oft_y_ROI_train = train_dict['y_ROI']\n",
    "oft_y_vel_train = train_dict['y_vel']\n",
    "oft_y_mouse_train = train_dict['y_mouse']\n",
    "oft_y_time_train = train_dict['y_time']\n",
    "\n",
    "#Validation Arrays\n",
    "oft_X_val = np.hstack([val_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "oft_y_hc_val = val_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_val = ~oft_y_hc_val\n",
    "oft_y_ROI_val = val_dict['y_ROI']\n",
    "oft_y_vel_val = val_dict['y_vel']\n",
    "oft_y_mouse_val = val_dict['y_mouse']\n",
    "oft_y_time_val = val_dict['y_time']\n",
    "\n",
    "#Test Arrays\n",
    "oft_X_test = np.hstack([test_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "oft_y_hc_test = test_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_test = ~oft_y_hc_test\n",
    "oft_y_ROI_test = test_dict['y_ROI']\n",
    "oft_y_vel_test = test_dict['y_vel']\n",
    "oft_y_mouse_test = test_dict['y_mouse']\n",
    "oft_y_time_test = test_dict['y_time']\n",
    "oft_y_expDate_test = test_dict['y_expDate']\n",
    "\n",
    "oft_X = np.vstack([oft_X_train,oft_X_val])\n",
    "oft_y_task = np.hstack([oft_y_task_train,oft_y_task_val])\n",
    "oft_y_mouse = np.hstack([oft_y_mouse_train,oft_y_mouse_val])\n",
    "\n",
    "with open(epm_data_path.format(\"train\"),\"rb\") as f:\n",
    "    epm_train_dict = pickle.load(f)\n",
    "\n",
    "with open(epm_data_path.format(\"val\"),\"rb\") as f:\n",
    "    epm_validation_dict = pickle.load(f)\n",
    "    \n",
    "with open(epm_data_path.format(\"test\"),\"rb\") as f:\n",
    "    epm_test_dict = pickle.load(f)\n",
    "\n",
    "#Load the data\n",
    "NUM_FREQS = 56\n",
    "NUM_FEATURES = (epm_train_dict[\"X_power_1_2\"].shape[1] + \\\n",
    "                epm_train_dict[\"X_coh_1_2\"].shape[1] + \\\n",
    "                epm_train_dict[\"X_gc_1_2\"].shape[1]) // NUM_FREQS\n",
    "SCALE_VECTOR = np.array([np.arange(1,57) for feature in range(NUM_FEATURES)]).flatten()\n",
    "\n",
    "X_train = np.hstack([epm_train_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "X_train[X_train<0] = 0\n",
    "y_train = (epm_train_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_train = ~epm_train_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_train = epm_train_dict['y_mouse']\n",
    "y_time_train = epm_train_dict['y_time']\n",
    "train_nan_mask = (epm_train_dict['y_ROI'] > 0)\n",
    "\n",
    "\n",
    "X_train_task = X_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_train_task = y_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_mouse_train_task = y_mouse_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_time_train_task = y_time_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "X_val = np.hstack([epm_validation_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "\n",
    "\n",
    "y_val = (epm_validation_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_val= ~epm_validation_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_val = epm_validation_dict['y_mouse']\n",
    "y_time_val = epm_validation_dict['y_time']\n",
    "val_nan_mask = (epm_validation_dict['y_ROI'] > 0)\n",
    "\n",
    "X_val_task = X_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_val_task = y_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_mouse_val_task = y_mouse_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_time_val_task = y_time_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "\n",
    "X_test = np.hstack([epm_test_dict[feature]*weight for feature,weight in zip(old_feature_list,feature_weights)])\n",
    "y_test = (epm_test_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_test= ~epm_test_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_test = epm_test_dict['y_mouse']\n",
    "y_time_test = epm_test_dict['y_time']\n",
    "test_nan_mask = (epm_test_dict['y_ROI'] > 0)\n",
    "epm_y_expDate_test = epm_test_dict['y_expDate']\n",
    "\n",
    "X_test_task = X_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_test_task = y_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_mouse_test_task = y_mouse_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_time_test_task = y_time_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "\n",
    "epm_X = np.vstack([X_train,X_val])\n",
    "epm_y_task = np.hstack([y_in_task_mask_train,y_in_task_mask_val])\n",
    "epm_y_mouse = np.hstack([y_mouse_train,y_mouse_val])\n",
    "epm_y_time = np.hstack([y_time_train,y_time_val])\n",
    "\n",
    "mt_X_train = np.vstack([flx_X,oft_X,epm_X])[:,56*featureIdx:56*(featureIdx+1)]\n",
    "mt_y_train = np.hstack([flx_y,oft_y_task,epm_y_task]).reshape(-1,1)\n",
    "mt_y_mouse_train = np.hstack([flx_y_mouse,oft_y_mouse,epm_y_mouse])\n",
    "\n",
    "mt_X_test = np.vstack([flx_X_test[flx_y_hab_test==1],oft_X_test,X_test])[:,56*featureIdx:56*(featureIdx+1)]\n",
    "mt_y_test = np.hstack([flx_y_test[flx_y_hab_test==1],oft_y_task_test,y_in_task_mask_test]).reshape(-1,1)\n",
    "mt_y_mouse_test = np.hstack([flx_y_mouse_test[flx_y_hab_test==1],oft_y_mouse_test,y_mouse_test])\n",
    "\n",
    "intercept_mask = OneHotEncoder().fit_transform(mt_y_mouse_train.reshape(-1,1)).todense()\n",
    "sample_groups = OrdinalEncoder().fit_transform(mt_y_mouse_train.reshape(-1,1))\n",
    "nmf_groups = np.hstack(\n",
    "    [\n",
    "        np.ones(flx_X.shape[0])*0,\n",
    "        np.ones(oft_X.shape[0]),\n",
    "        np.ones(epm_X.shape[0])*2\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae761b9-b068-4aff-a97c-4c49cca64989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55657, 56) (55657, 3)\n",
      "Pretraining NMF...\n",
      "Identifying predictive components for supervised network 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting network: 19 with auc 0.4219296457129364 for sup net 0 using constraint n/a correlation\n",
      "Identifying predictive components for supervised network 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting network: 5 with auc 0.424857721552915 for sup net 1 using constraint n/a correlation\n",
      "Identifying predictive components for supervised network 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 12.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting network: 17 with auc 0.4353525179750406 for sup net 2 using constraint n/a correlation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder Pretrain Epoch: 199, Recon Loss: 0.131861: 100%|██████████| 200/200 [08:15<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 199, Current Training MSE: 0.00166854, Current Training by Window ROC-AUC: [0.562198744428256]: 100%|██████████| 200/200 [11:37<00:00,  3.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the last epoch with training MSE: 0.00166854 and AUCs:[0.562198744428256]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN = True\n",
    "\n",
    "for n_components in [30]:\n",
    "    if TRAIN:\n",
    "        model = DcsfaNmf(\n",
    "            n_components=n_components,\n",
    "            n_sup_networks=3,\n",
    "            sup_type=\"sc\",\n",
    "            n_intercepts=intercept_mask.shape[1],\n",
    "            optim_name=\"SGD\",\n",
    "            recon_loss=\"MSE\",\n",
    "            save_folder=saved_model_path,\n",
    "        )\n",
    "\n",
    "        model.fit(mt_X_train,\n",
    "                  mt_y_train,\n",
    "                  intercept_mask=intercept_mask,\n",
    "                  y_sample_groups=sample_groups,\n",
    "                  batch_size=128,\n",
    "                  lr=1e-3,\n",
    "                  n_pre_epochs=200,\n",
    "                  n_epochs=200,\n",
    "                  nmf_max_iter=20000,\n",
    "                  nmf_groups=nmf_groups,\n",
    "                  bootstrap=True,\n",
    "                  pretrain=True,\n",
    "                  verbose=True,\n",
    "                  best_model_name=saved_model_name.format(currentFeature,n_components))\n",
    "\n",
    "        torch.save(model,saved_model_path + saved_model_name.format(currentFeature,n_components))\n",
    "    else:\n",
    "        model = torch.load(saved_model_path + saved_model_name.format(currentFeature,n_components),map_location=\"cpu\")\n",
    "        model.device=\"cpu\"\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e4b7487-3df4-43fe-947c-a3e0dfacf44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea63bd9-c3fe-4696-9f20-cca5375dcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(model.recon_hist,label=\"training recon\")\n",
    "#plt.plot(model.val_recon_hist,label=\"validation recon\")\n",
    "#plt.axvline(model.best_epoch,color=\"red\",label=\"best epoch\")\n",
    "plt.title(\"Training Reconstruction Performance (After Pretraining)\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(model.pred_hist,label=\"training auc\")\n",
    "#plt.plot(model.val_pred_hist,label=\"validation auc\")\n",
    "#plt.axvline(model.best_epoch,color=\"red\",label=\"best epoch\")\n",
    "plt.title(\"Training Prediction Performance (After Pretraining)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7bc39ca-02db-4f23-9983-7aaa96f54ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLX test auc: 0.488 +/- 0.007\n",
      "{'Mouse69061': [0.5098491649163174], 'Mouse78732': [0.45758164695878], 'Mouse78743': [0.4878354471544715], 'Mouse78745': [0.4806531392676226], 'Mouse78751': [0.5050238659509261], 'Mouse78764': [0.4846497333083797]}\n"
     ]
    }
   ],
   "source": [
    "flx_test_auc = model.score(flx_X_test[flx_y_hab_test==1,56*featureIdx:56*(featureIdx+1)],\n",
    "                          flx_y_test[flx_y_hab_test==1].reshape(-1,1),\n",
    "                            flx_y_mouse_test[flx_y_hab_test==1],\n",
    "                            return_dict=True)\n",
    "                                     \n",
    "flx_mean_test_auc = np.mean([flx_test_auc[key] for key in flx_test_auc.keys()])\n",
    "flx_stderr_test_auc = np.std([flx_test_auc[key] for key in flx_test_auc.keys()]) / np.sqrt(len(flx_test_auc.keys()))\n",
    "\n",
    "print(\"FLX test auc: {:.3f} +/- {:.3f}\".format(flx_mean_test_auc,flx_stderr_test_auc))\n",
    "print(flx_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91e6b24-71e0-40a6-a780-cf3c94c1e8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPM test auc: 0.560 +/- 0.022\n",
      "{'Mouse0641': [0.5251726121979285], 'Mouse39115': [0.7168694078616669], 'Mouse39121': [0.5881693660695549], 'Mouse39122': [0.6060309319980617], 'Mouse39132': [0.5135451110061408], 'Mouse39135': [0.5969837959249158], 'Mouse6674': [0.5095533498759305], 'Mouse69061': [0.4374369729150863], 'Mouse69071': [0.4842178715654446], 'Mouse69075': [0.6203367172160255], 'Mouse8893': [0.5629821894628158]}\n"
     ]
    }
   ],
   "source": [
    "epm_test_auc = model.score(X_test[:,56*featureIdx:56*(featureIdx+1)],\n",
    "                          y_in_task_mask_test.reshape(-1,1),\n",
    "                          y_mouse_test,\n",
    "                          return_dict=True)\n",
    "\n",
    "epm_mean_test_auc = np.mean([epm_test_auc[key] for key in epm_test_auc.keys()])\n",
    "epm_stderr_test_auc = np.std([epm_test_auc[key] for key in epm_test_auc.keys()]) / np.sqrt(len(epm_test_auc.keys()))\n",
    "\n",
    "print(\"EPM test auc: {:.3f} +/- {:.3f}\".format(epm_mean_test_auc,epm_stderr_test_auc))\n",
    "print(epm_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "452f64d9-462e-4caf-bf37-2d9662d03f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFT test auc: 0.660 +/- 0.036\n",
      "{'Mouse04203': [0.8456728222205403], 'Mouse39115': [0.7618146088957055], 'Mouse39121': [0.7685112606025154], 'Mouse39122': [0.5702672860188851], 'Mouse39132': [0.654817535699537], 'Mouse39135': [0.6145478886595637], 'Mouse69061': [0.46878922078387786], 'Mouse69071': [0.6162384127500407], 'Mouse69075': [0.6397872506234413]}\n"
     ]
    }
   ],
   "source": [
    "oft_test_auc = model.score(oft_X_test[:,56*featureIdx:56*(featureIdx+1)],\n",
    "                            oft_y_task_test.reshape(-1,1),\n",
    "                            oft_y_mouse_test,\n",
    "                            return_dict=True)\n",
    "\n",
    "oft_mean_test_auc = np.mean([oft_test_auc[key] for key in oft_test_auc.keys()])\n",
    "oft_stderr_test_auc = np.std([oft_test_auc[key] for key in oft_test_auc.keys()]) / np.sqrt(len(oft_test_auc.keys()))\n",
    "print(\"OFT test auc: {:.3f} +/- {:.3f}\".format(oft_mean_test_auc,oft_stderr_test_auc))\n",
    "print(oft_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65954688-8734-48cd-9aaa-86f1d549657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = model.project(mt_X_test)\n",
    "X_recon = model.reconstruct(mt_X_test)+ EPSILON\n",
    "perc_recon_list = []\n",
    "for i in range(3):\n",
    "    X_sup_recon = model.get_comp_recon(torch.Tensor(s).to(model.device),i) + EPSILON\n",
    "    net_recon_contribution = np.mean(X_sup_recon/X_recon,axis=0) \n",
    "    perc_recon_list.append(net_recon_contribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe8eda30-bb05-40ba-bac1-18a8bd3893b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    \"flx_auc\":flx_test_auc,\n",
    "    \"flx_mean_test_auc\":flx_mean_test_auc,\n",
    "    \"flx_stderr_test_auc\":flx_stderr_test_auc,\n",
    "    \n",
    "    \"epm_auc\":epm_test_auc,\n",
    "    \"epm_mean_test_auc\":epm_mean_test_auc,\n",
    "    \"epm_stderr_test_auc\":epm_stderr_test_auc,\n",
    "    \n",
    "    \"oft_auc\":oft_test_auc,\n",
    "    \"oft_mean_test_auc\":oft_mean_test_auc,\n",
    "    \"oft_stderr_test_auc\":oft_stderr_test_auc,\n",
    "    \n",
    "    \"n_components\":n_components,\n",
    "    \"coefficients\":model.classifier[0].weight[0].detach().cpu().numpy(),\n",
    "    \"s_avg\":np.mean(s,axis=0)[:3],\n",
    "    \"feature\":currentFeature,\n",
    "}\n",
    "\n",
    "with open(results_file.format(currentFeature,n_components),\"wb\") as f:\n",
    "    pickle.dump(results_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcc1fc9a-c4ac-4591-b6f7-974f3b9123df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4240, -0.1858, -0.1920], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "376968cd-d925-44ae-af75-daadf8eaa93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03321023, 0.03113751, 0.02753031], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(s,axis=0)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c31fb-98a7-47eb-8421-fca64ed57445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
