{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc847bd-a57c-4e3e-ab2e-e19785e5e5b7",
   "metadata": {},
   "source": [
    "## Data Organization\n",
    "\n",
    "Created on January 25th 2023 by Hunter Klein\n",
    "\n",
    "\n",
    "Created a single dictionary with all features used for network generation. Power features are multiplied by 10. This is to make other notebooks for network discovery and hyperparameter validation cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa1f94fc-4297-4abf-9805-47acb04f5515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"/work/mk423/Anxiety/\"\n",
    "sys.path.append(DATA_PATH)\n",
    "FLX_TRAIN_FILE = DATA_PATH + \"FLX_train_dict_old_features.pkl\"\n",
    "FLX_VAL_FILE = DATA_PATH + \"FLX_validation_dict_old_features.pkl\"\n",
    "FLX_TEST_FILE = DATA_PATH + \"FLX_test_dict_old_features.pkl\"\n",
    "\n",
    "EPM_TRAIN_FILE = DATA_PATH + \"EPM_train_dict_May_17.pkl\"\n",
    "EPM_VAL_FILE = DATA_PATH + \"EPM_val_dict_May_17.pkl\"\n",
    "EPM_TEST_FILE = DATA_PATH + \"EPM_test_dict_May_17.pkl\"\n",
    "\n",
    "OFT_TRAIN_FILE = DATA_PATH + \"OFT_train_dict_old_features_hand_picked.pkl\"\n",
    "OFT_VAL_FILE = DATA_PATH + \"OFT_validation_dict_old_features_hand_picked.pkl\"\n",
    "OFT_TEST_FILE = DATA_PATH + \"OFT_test_dict_old_features_hand_picked.pkl\"\n",
    "\n",
    "OFT_PROJECTION_FILE = \"G:\\\\Anxiety_Datasets\\\\new_OFT\\\\oft_flx_projection_data.pkl\"\n",
    "FEATURE_LIST = ['X_power_1_2','X_coh_1_2','X_gc_1_2']\n",
    "FEATURE_VECTOR = FEATURE_LIST\n",
    "FEATURE_WEIGHT = [10,1,1]\n",
    "\n",
    "\n",
    "FEATURE_LIST = ['X_power_1_2','X_coh_1_2','X_gc_1_2']\n",
    "#FEATURE_LIST = ['X_psd','X_ds']\n",
    "FEATURE_VECTOR = FEATURE_LIST\n",
    "FEATURE_WEIGHT = [10,1,1]\n",
    "\n",
    "UMC_PATH = \"/hpc/home/mk423/Anxiety/Universal-Mouse-Code\"\n",
    "\n",
    "sys.path.append(UMC_PATH)\n",
    "#from dCSFA_model import dCSFA_model\n",
    "import umc_data_tools as umc_dt\n",
    "from dCSFA_NMF import dCSFA_NMF\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device=\"cuda:0\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "\n",
    "\n",
    "print(\"Using device: %s\"%(device))\n",
    "\n",
    "#For Consistency\n",
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c766a839-3836-425e-9926-4e1251f35301",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OFT_TRAIN_FILE,'rb') as f:\n",
    "    train_dict = pickle.load(f)\n",
    "\n",
    "with open(OFT_VAL_FILE,'rb') as f:\n",
    "    val_dict = pickle.load(f)\n",
    "\n",
    "with open(OFT_TEST_FILE,'rb') as f:\n",
    "    test_dict = pickle.load(f)\n",
    "    \n",
    "running_idx = 0\n",
    "feature_groups = []\n",
    "for idx,feature in enumerate(FEATURE_LIST):\n",
    "    f_begin = running_idx\n",
    "    f_end = f_begin + train_dict[feature].shape[1] \n",
    "    if idx == 0:\n",
    "        f_end = f_end -1\n",
    "    feature_groups.append((f_begin,f_end))\n",
    "\n",
    "    running_idx = f_end\n",
    "\n",
    "NUM_FREQS = 56\n",
    "NUM_FEATURES = np.hstack([train_dict[feature] for feature in FEATURE_LIST]).shape[1] // NUM_FREQS\n",
    "scale_vector = np.array([np.arange(1,NUM_FREQS+1) for feature in range(NUM_FEATURES)]).flatten()\n",
    "\n",
    "#Train Arrays\n",
    "oft_X_train = np.hstack([train_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])#*scale_vector\n",
    "#oft_X_train[np.isnan(oft_X_train)] = 0\n",
    "#oft_X_train[oft_X_train<0] = 0\n",
    "oft_y_hc_train = train_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_train = ~oft_y_hc_train\n",
    "oft_y_ROI_train = train_dict['y_ROI']\n",
    "oft_y_vel_train = train_dict['y_vel']\n",
    "oft_y_mouse_train = train_dict['y_mouse']\n",
    "oft_y_time_train = train_dict['y_time']\n",
    "\n",
    "#Validation Arrays\n",
    "oft_X_val = np.hstack([val_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])#*scale_vector\n",
    "oft_y_hc_val = val_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_val = ~oft_y_hc_val\n",
    "oft_y_ROI_val = val_dict['y_ROI']\n",
    "oft_y_vel_val = val_dict['y_vel']\n",
    "oft_y_mouse_val = val_dict['y_mouse']\n",
    "oft_y_time_val = val_dict['y_time']\n",
    "\n",
    "oft_X_test = np.hstack([test_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "oft_y_hc_test = test_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_test = ~oft_y_hc_test\n",
    "oft_y_ROI_test = test_dict['y_ROI']\n",
    "oft_y_vel_test = test_dict['y_vel']\n",
    "oft_y_mouse_test = test_dict['y_mouse']\n",
    "oft_y_time_test = test_dict['y_time']\n",
    "\n",
    "oft_X = np.vstack([oft_X_train,oft_X_val])\n",
    "oft_y_task = np.hstack([oft_y_task_train,oft_y_task_val])\n",
    "oft_y_mouse = np.hstack([oft_y_mouse_train,oft_y_mouse_val])\n",
    "\n",
    "with open(FLX_TRAIN_FILE,\"rb\") as f:\n",
    "    flx_train_dict = pickle.load(f)\n",
    "\n",
    "with open(FLX_VAL_FILE,\"rb\") as f:\n",
    "    flx_validation_dict = pickle.load(f)\n",
    "\n",
    "with open(FLX_TEST_FILE,\"rb\") as f:\n",
    "    flx_test_dict = pickle.load(f)\n",
    "\n",
    "flx_X_train = np.hstack([flx_train_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "flx_y_train = flx_train_dict['y_flx']\n",
    "flx_y_mouse_train = flx_train_dict['y_mouse']\n",
    "flx_y_expDate_train = flx_train_dict['y_expDate']\n",
    "flx_y_time_train = flx_train_dict['y_time']\n",
    "\n",
    "flx_X_validation = np.hstack([flx_validation_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "flx_y_validation = flx_validation_dict['y_flx']\n",
    "flx_y_mouse_validation = flx_validation_dict['y_mouse']\n",
    "flx_y_expDate_validation = flx_validation_dict['y_expDate']\n",
    "flx_y_time_validation = flx_validation_dict['y_time']\n",
    "\n",
    "flx_X_test = np.hstack([flx_test_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "flx_y_test = flx_test_dict['y_flx']\n",
    "flx_y_mouse_test = flx_test_dict['y_mouse']\n",
    "flx_y_expDate_test = flx_test_dict['y_expDate']\n",
    "flx_y_time_test = flx_test_dict['y_time']\n",
    "\n",
    "flx_X = np.vstack([flx_X_train,flx_X_validation])\n",
    "flx_y_task = np.hstack([flx_y_train,flx_y_validation])\n",
    "flx_y_mouse = np.hstack([flx_y_mouse_train,flx_y_mouse_validation])\n",
    "flx_y_expDate = np.hstack([flx_y_expDate_train,flx_y_expDate_validation])\n",
    "flx_y_time = np.hstack([flx_y_time_train,flx_y_time_validation])\n",
    "\n",
    "with open(EPM_TRAIN_FILE,\"rb\") as f:\n",
    "    epm_train_dict = pickle.load(f)\n",
    "\n",
    "with open(EPM_VAL_FILE,\"rb\") as f:\n",
    "    epm_validation_dict = pickle.load(f)\n",
    "\n",
    "with open(EPM_TEST_FILE,\"rb\") as f:\n",
    "    epm_test_dict = pickle.load(f)\n",
    "\n",
    "#Load the data\n",
    "NUM_FREQS = 56\n",
    "NUM_FEATURES = (epm_train_dict[\"X_power_1_2\"].shape[1] + \\\n",
    "                epm_train_dict[\"X_coh_1_2\"].shape[1] + \\\n",
    "                epm_train_dict[\"X_gc_1_2\"].shape[1]) // NUM_FREQS\n",
    "SCALE_VECTOR = np.array([np.arange(1,57) for feature in range(NUM_FEATURES)]).flatten()\n",
    "\n",
    "X_train = np.hstack([epm_train_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "#X_train[X_train<0] = 0\n",
    "y_train = (epm_train_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_train = ~epm_train_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_train = epm_train_dict['y_mouse']\n",
    "y_time_train = epm_train_dict['y_time']\n",
    "train_nan_mask = (epm_train_dict['y_ROI'] > 0)\n",
    "\n",
    "\n",
    "X_train_task = X_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_train_task = y_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_mouse_train_task = y_mouse_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_time_train_task = y_time_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "\n",
    "X_val = np.hstack([epm_validation_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "y_val = (epm_validation_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_val= ~epm_validation_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_val = epm_validation_dict['y_mouse']\n",
    "y_time_val = epm_validation_dict['y_time']\n",
    "val_nan_mask = (epm_validation_dict['y_ROI'] > 0)\n",
    "\n",
    "X_val_task = X_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_val_task = y_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_mouse_val_task = y_mouse_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_time_val_task = y_time_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "\n",
    "X_test = np.hstack([epm_test_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "y_test = (epm_test_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_test= ~epm_test_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_test = epm_test_dict['y_mouse']\n",
    "y_time_test = epm_test_dict['y_time']\n",
    "test_nan_mask = (epm_test_dict['y_ROI'] > 0)\n",
    "\n",
    "X_test_task = X_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_test_task = y_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_mouse_test_task = y_mouse_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_time_test_task = y_time_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "\n",
    "epm_X = np.vstack([X_train_task,X_val_task])\n",
    "epm_y_task = np.hstack([y_train_task,y_val_task])\n",
    "epm_y_mouse = np.hstack([y_mouse_train_task,y_mouse_val_task])\n",
    "epm_y_time = np.hstack([y_time_train_task,y_time_val_task])\n",
    "\n",
    "mt_X_train = np.vstack([flx_X_train,oft_X_train,X_train])\n",
    "mt_y_train = np.hstack([flx_y_train,oft_y_task_train,y_in_task_mask_train])\n",
    "mt_y_mouse_train = np.hstack([flx_y_mouse_train,oft_y_mouse_train,y_mouse_train])\n",
    "mt_y_exp_train = np.hstack([[\"flx\" for i in range(flx_X_train.shape[0])],\n",
    "                            [\"oft\" for i in range(oft_X_train.shape[0])],\n",
    "                            [\"epm\" for i in range(X_train.shape[0])]])\n",
    "\n",
    "mt_X_val = np.vstack([flx_X_validation,oft_X_val,X_val])\n",
    "mt_y_val = np.hstack([flx_y_validation,oft_y_task_val,y_in_task_mask_val])\n",
    "mt_y_mouse_val = np.hstack([flx_y_mouse_validation,oft_y_mouse_val,y_mouse_val])\n",
    "\n",
    "mt_y_exp_val = np.hstack([[\"flx\" for i in range(flx_X_validation.shape[0])],\n",
    "                            [\"oft\" for i in range(oft_X_val.shape[0])],\n",
    "                            [\"epm\" for i in range(X_val.shape[0])]])\n",
    "\n",
    "mt_X_test = np.vstack([flx_X_test,oft_X_test,X_test])\n",
    "mt_y_test = np.hstack([flx_y_test,oft_y_task_test,y_in_task_mask_test])\n",
    "mt_y_mouse_test = np.hstack([flx_y_mouse_test,oft_y_mouse_test,y_mouse_test])\n",
    "mt_y_exp_test = np.hstack([[\"flx\" for i in range(flx_X_test.shape[0])],\n",
    "                            [\"oft\" for i in range(oft_X_test.shape[0])],\n",
    "                            [\"epm\" for i in range(X_test.shape[0])]])\n",
    "\n",
    "intercept_mask_train = OneHotEncoder().fit_transform(mt_y_mouse_train.reshape(-1,1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9417e4-b1f0-44b9-a9c0-5797bb7fd65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/work/mk423/Anxiety/anx_info_dict.pkl\",\"rb\") as f:\n",
    "    anx_info_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8fa61b8-ac58-42f4-ae7d-2d3db3e68054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['channel', 'channelArea', 'allWindows', 'fsRaw', 'windowLength', 'windows', 'area', 's', 'fs', 'preprocessVersion', 'f', 'powerFeatures', 'powVersion', 'cohFeatures', 'cohVersion', 'gcFeatures', 'instFeatures', 'gcVersion'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anx_info_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a108fc7-1d3d-4c55-b539-9076a094929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_dict = {\n",
    "    \"X_train\":mt_X_train,\n",
    "    \"y_train\":mt_y_train,\n",
    "    \"y_mouse_train\":mt_y_mouse_train,\n",
    "    \"y_exp_train\":mt_y_exp_train,\n",
    "    \n",
    "    \"X_val\":mt_X_val,\n",
    "    \"y_val\":mt_y_val,\n",
    "    \"y_mouse_val\":mt_y_mouse_val,\n",
    "    \"y_exp_val\":mt_y_exp_val,\n",
    "    \n",
    "    \"X_test\":mt_X_test,\n",
    "    \"y_test\":mt_y_test,\n",
    "    \"y_mouse_test\":mt_y_mouse_test,\n",
    "    \"y_exp_test\":mt_y_exp_test,\n",
    "    \n",
    "    \"anx_info_dict\":anx_info_dict,\n",
    "    \"feature_groups\":feature_groups,\n",
    "    \"feature_weights\":FEATURE_WEIGHT\n",
    "}\n",
    "\n",
    "with open(DATA_PATH + \"Anxiety_Network_Generation_Data.pkl\",\"wb\") as f:\n",
    "    pickle.dump(unified_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d5433-a36f-4243-8422-90895e685445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
