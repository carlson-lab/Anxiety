{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e2f1fc9-fcd2-48a5-80f6-20f9ef97160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lpne.models import DcsfaNmf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a45b395-3327-4a3f-9329-e047c2bebb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LOCATION = \"/work/mk423/Anxiety/\"\n",
    "UMC_PATH = \"/hpc/home/mk423/Anxiety/Universal-Mouse-Code/\"\n",
    "INFO_DICT = DATA_LOCATION + \"Anx_Info_Dict.pkl\"\n",
    "\n",
    "FLX_TRAIN_FILE = DATA_LOCATION + \"FLX_train_dict_old_features.pkl\"\n",
    "FLX_VAL_FILE = DATA_LOCATION + \"FLX_validation_dict_old_features.pkl\"\n",
    "FLX_TEST_FILE = DATA_LOCATION + \"FLX_test_dict_old_features.pkl\"\n",
    "\n",
    "EPM_TRAIN_FILE = DATA_LOCATION + \"EPM_train_dict_May_17.pkl\"\n",
    "EPM_VAL_FILE = DATA_LOCATION + \"EPM_val_dict_May_17.pkl\"\n",
    "EPM_TEST_FILE = DATA_LOCATION + \"EPM_test_dict_May_17.pkl\"\n",
    "\n",
    "OFT_TRAIN_FILE = DATA_LOCATION + \"OFT_train_dict_old_features_hand_picked.pkl\"\n",
    "OFT_VAL_FILE = DATA_LOCATION + \"OFT_validation_dict_old_features_hand_picked.pkl\"\n",
    "OFT_TEST_FILE = DATA_LOCATION + \"OFT_test_dict_old_features_hand_picked.pkl\"\n",
    "\n",
    "FEATURE_LIST = ['X_power_1_2','X_coh_1_2','X_gc_1_2']\n",
    "FEATURE_VECTOR = FEATURE_LIST\n",
    "FEATURE_WEIGHT = [10,1,1]\n",
    "\n",
    "sys.path.append(UMC_PATH)\n",
    "sys.path.append(DATA_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d6ec7b1-3e76-43d7-8132-222e5503cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OFT_TRAIN_FILE,'rb') as f:\n",
    "    train_dict = pickle.load(f)\n",
    "\n",
    "with open(OFT_VAL_FILE,'rb') as f:\n",
    "    val_dict = pickle.load(f)\n",
    "\n",
    "with open(OFT_TEST_FILE,'rb') as f:\n",
    "    test_dict = pickle.load(f)\n",
    "    \n",
    "running_idx = 0\n",
    "feature_groups = []\n",
    "for idx,feature in enumerate(FEATURE_LIST):\n",
    "    f_begin = running_idx\n",
    "    f_end = f_begin + train_dict[feature].shape[1] \n",
    "    if idx == 0:\n",
    "        f_end = f_end -1\n",
    "    feature_groups.append((f_begin,f_end))\n",
    "\n",
    "    running_idx = f_end\n",
    "\n",
    "NUM_FREQS = 56\n",
    "NUM_FEATURES = np.hstack([train_dict[feature] for feature in FEATURE_LIST]).shape[1] // NUM_FREQS\n",
    "scale_vector = np.array([np.arange(1,NUM_FREQS+1) for feature in range(NUM_FEATURES)]).flatten()\n",
    "\n",
    "#Train Arrays\n",
    "oft_X_train = np.hstack([train_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])#*scale_vector\n",
    "#oft_X_train[np.isnan(oft_X_train)] = 0\n",
    "#oft_X_train[oft_X_train<0] = 0\n",
    "oft_y_hc_train = train_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_train = ~oft_y_hc_train\n",
    "oft_y_ROI_train = train_dict['y_ROI']\n",
    "oft_y_vel_train = train_dict['y_vel']\n",
    "oft_y_mouse_train = train_dict['y_mouse']\n",
    "oft_y_time_train = train_dict['y_time']\n",
    "\n",
    "#Validation Arrays\n",
    "oft_X_val = np.hstack([val_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])#*scale_vector\n",
    "oft_y_hc_val = val_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_val = ~oft_y_hc_val\n",
    "oft_y_ROI_val = val_dict['y_ROI']\n",
    "oft_y_vel_val = val_dict['y_vel']\n",
    "oft_y_mouse_val = val_dict['y_mouse']\n",
    "oft_y_time_val = val_dict['y_time']\n",
    "\n",
    "oft_X_test = np.hstack([test_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "oft_y_hc_test = test_dict['y_Homecage'].astype(bool)\n",
    "oft_y_task_test = ~oft_y_hc_test\n",
    "oft_y_ROI_test = test_dict['y_ROI']\n",
    "oft_y_vel_test = test_dict['y_vel']\n",
    "oft_y_mouse_test = test_dict['y_mouse']\n",
    "oft_y_time_test = test_dict['y_time']\n",
    "\n",
    "oft_X = np.vstack([oft_X_train,oft_X_val])\n",
    "oft_y_task = np.hstack([oft_y_task_train,oft_y_task_val])\n",
    "oft_y_mouse = np.hstack([oft_y_mouse_train,oft_y_mouse_val])\n",
    "\n",
    "with open(FLX_TRAIN_FILE,\"rb\") as f:\n",
    "    flx_train_dict = pickle.load(f)\n",
    "\n",
    "with open(FLX_VAL_FILE,\"rb\") as f:\n",
    "    flx_validation_dict = pickle.load(f)\n",
    "\n",
    "with open(FLX_TEST_FILE,\"rb\") as f:\n",
    "    flx_test_dict = pickle.load(f)\n",
    "\n",
    "flx_X_train = np.hstack([flx_train_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "flx_y_train = flx_train_dict['y_flx']\n",
    "flx_y_mouse_train = flx_train_dict['y_mouse']\n",
    "flx_y_expDate_train = flx_train_dict['y_expDate']\n",
    "flx_y_time_train = flx_train_dict['y_time']\n",
    "\n",
    "flx_X_validation = np.hstack([flx_validation_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "flx_y_validation = flx_validation_dict['y_flx']\n",
    "flx_y_mouse_validation = flx_validation_dict['y_mouse']\n",
    "flx_y_expDate_validation = flx_validation_dict['y_expDate']\n",
    "flx_y_time_validation = flx_validation_dict['y_time']\n",
    "\n",
    "flx_X_test = np.hstack([flx_test_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "flx_y_test = flx_test_dict['y_flx']\n",
    "flx_y_mouse_test = flx_test_dict['y_mouse']\n",
    "flx_y_expDate_test = flx_test_dict['y_expDate']\n",
    "flx_y_time_test = flx_test_dict['y_time']\n",
    "\n",
    "flx_X = np.vstack([flx_X_train,flx_X_validation])\n",
    "flx_y_task = np.hstack([flx_y_train,flx_y_validation])\n",
    "flx_y_mouse = np.hstack([flx_y_mouse_train,flx_y_mouse_validation])\n",
    "flx_y_expDate = np.hstack([flx_y_expDate_train,flx_y_expDate_validation])\n",
    "flx_y_time = np.hstack([flx_y_time_train,flx_y_time_validation])\n",
    "\n",
    "with open(EPM_TRAIN_FILE,\"rb\") as f:\n",
    "    epm_train_dict = pickle.load(f)\n",
    "\n",
    "with open(EPM_VAL_FILE,\"rb\") as f:\n",
    "    epm_validation_dict = pickle.load(f)\n",
    "\n",
    "with open(EPM_TEST_FILE,\"rb\") as f:\n",
    "    epm_test_dict = pickle.load(f)\n",
    "\n",
    "#Load the data\n",
    "NUM_FREQS = 56\n",
    "NUM_FEATURES = (epm_train_dict[\"X_power_1_2\"].shape[1] + \\\n",
    "                epm_train_dict[\"X_coh_1_2\"].shape[1] + \\\n",
    "                epm_train_dict[\"X_gc_1_2\"].shape[1]) // NUM_FREQS\n",
    "SCALE_VECTOR = np.array([np.arange(1,57) for feature in range(NUM_FEATURES)]).flatten()\n",
    "\n",
    "X_train = np.hstack([epm_train_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "#X_train[X_train<0] = 0\n",
    "y_train = (epm_train_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_train = ~epm_train_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_train = epm_train_dict['y_mouse']\n",
    "y_time_train = epm_train_dict['y_time']\n",
    "train_nan_mask = (epm_train_dict['y_ROI'] > 0)\n",
    "\n",
    "\n",
    "X_train_task = X_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_train_task = y_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_mouse_train_task = y_mouse_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "y_time_train_task = y_time_train[np.logical_and(y_in_task_mask_train==1,train_nan_mask)==1]\n",
    "\n",
    "X_val = np.hstack([epm_validation_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "y_val = (epm_validation_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_val= ~epm_validation_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_val = epm_validation_dict['y_mouse']\n",
    "y_time_val = epm_validation_dict['y_time']\n",
    "val_nan_mask = (epm_validation_dict['y_ROI'] > 0)\n",
    "\n",
    "X_val_task = X_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_val_task = y_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_mouse_val_task = y_mouse_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "y_time_val_task = y_time_val[np.logical_and(y_in_task_mask_val==1,val_nan_mask)==1]\n",
    "\n",
    "X_test = np.hstack([epm_test_dict[feature]*weight for feature,weight in zip(FEATURE_LIST,FEATURE_WEIGHT)])\n",
    "y_test = (epm_test_dict['y_ROI']%2).astype(bool)\n",
    "y_in_task_mask_test= ~epm_test_dict['y_Homecage'].astype(bool)\n",
    "y_mouse_test = epm_test_dict['y_mouse']\n",
    "y_time_test = epm_test_dict['y_time']\n",
    "test_nan_mask = (epm_test_dict['y_ROI'] > 0)\n",
    "\n",
    "X_test_task = X_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_test_task = y_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_mouse_test_task = y_mouse_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "y_time_test_task = y_time_test[np.logical_and(y_in_task_mask_test==1,test_nan_mask)==1]\n",
    "\n",
    "epm_X = np.vstack([X_train_task,X_val_task])\n",
    "epm_y_task = np.hstack([y_train_task,y_val_task])\n",
    "epm_y_mouse = np.hstack([y_mouse_train_task,y_mouse_val_task])\n",
    "epm_y_time = np.hstack([y_time_train_task,y_time_val_task])\n",
    "\n",
    "mt_X_train = np.vstack([flx_X_train,oft_X_train,X_train])\n",
    "mt_y_train = np.hstack([flx_y_train,oft_y_task_train,y_in_task_mask_train])\n",
    "mt_y_mouse_train = np.hstack([flx_y_mouse_train,oft_y_mouse_train,y_mouse_train])\n",
    "\n",
    "mt_X_val = np.vstack([flx_X_validation,oft_X_val,X_val])\n",
    "mt_y_val = np.hstack([flx_y_validation,oft_y_task_val,y_in_task_mask_val])\n",
    "mt_y_mouse_val = np.hstack([flx_y_mouse_validation,oft_y_mouse_val,y_mouse_val])\n",
    "\n",
    "mt_X_test = np.vstack([flx_X_test,oft_X_test,X_test])\n",
    "mt_y_test = np.hstack([flx_y_test,oft_y_task_test,y_in_task_mask_test])\n",
    "mt_y_mouse_test = np.hstack([flx_y_mouse_test,oft_y_mouse_test,y_mouse_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb53a09-1c2c-405e-ae9a-644f5d827fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INFO_DICT,\"rb\") as f:\n",
    "    anx_info_dict = pickle.load(f)\n",
    "    \n",
    "anx_info_dict.keys()\n",
    "\n",
    "powerFeatures = anx_info_dict['powerFeatures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc96f3b4-516c-4566-bb2a-430eefd2a6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(3)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e20d2-ea28-4a63-a588-a6ea9ecfcb34",
   "metadata": {},
   "source": [
    "### Get power feature predictiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f71fd65-d6dd-47fb-8e9a-44dce9866cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amy , auc 0.6082525212323433, n_net 23\n",
      "Cg_Cx , auc 0.6426362589171812, n_net 26\n",
      "Hipp , auc 0.5291109075854437, n_net 13\n",
      "IL_Cx , auc 0.6575092241299614, n_net 21\n",
      "Nac , auc 0.6593732728889709, n_net 29\n",
      "PrL_Cx , auc 0.6113448963918056, n_net 23\n",
      "Thal , auc 0.5833184102732732, n_net 5\n",
      "VTA , auc 0.570700160878049, n_net 10\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N_EPOCHS = 1#1500\n",
    "N_PRE_EPOCHS = 1#500\n",
    "VERBOSE = False\n",
    "PRETRAIN = False\n",
    "flx_val_mean_list = []\n",
    "flx_val_std_err_list = []\n",
    "epm_val_mean_list = []\n",
    "epm_val_std_err_list = []\n",
    "oft_val_mean_list = []\n",
    "oft_val_std_err_list = []\n",
    "\n",
    "val_data_tuples = [(\"flx\",np.vstack((flx_X_validation,flx_X_test)),np.hstack((flx_y_validation,flx_y_test)),np.hstack((flx_y_mouse_validation,flx_y_mouse_test))),\n",
    "                   (\"epm\",np.vstack((X_val,X_test)),np.hstack((y_in_task_mask_val,y_in_task_mask_test)),np.hstack((y_mouse_val,y_mouse_test))),\n",
    "                   (\"oft\",np.vstack((oft_X_val,oft_X_test)),np.hstack((oft_y_task_val,oft_y_task_test)),np.hstack((oft_y_mouse_val,oft_y_mouse_test)))]\n",
    "\n",
    "\n",
    "results_auc_dict = {}\n",
    "results_auc_dict[\"feature\"] = []\n",
    "results_auc_dict[\"auc\"] = []\n",
    "results_auc_dict[\"n_networks\"] = []\n",
    "\n",
    "for area in anx_info_dict['area']:\n",
    "    val_auc_list = []\n",
    "    \n",
    "    freq_check = [area + ' ' + str(freq) for freq in range(56)]\n",
    "    feature_mask = np.array([powerFeature in freq_check for powerFeature in powerFeatures])\n",
    "    x_power = mt_X_train[:,:len(powerFeatures)][:,feature_mask==1]\n",
    "    x_power_val = mt_X_val[:,:len(powerFeatures)][:,feature_mask==1]\n",
    "    \n",
    "    for n_networks in range(2,30):\n",
    "        \n",
    "        model = DcsfaNmf(\n",
    "            n_components=n_networks,\n",
    "            n_intercepts = np.unique(mt_y_mouse_train).shape[0],\n",
    "            optim_name=\"SGD\",\n",
    "            sup_recon_weight=0.01,\n",
    "            sup_recon_type=\"All\",\n",
    "            save_folder = \"/work/mk423/Anxiety/singleFeaturedCSFAModels/\",\n",
    "            fixed_corr=[\"positive\"],\n",
    "        )\n",
    "        \n",
    "        model.fit(x_power,\n",
    "                  mt_y_train.reshape(-1,1),\n",
    "                  intercept_mask=OneHotEncoder().fit_transform(mt_y_mouse_train.reshape(-1,1)).todense(),\n",
    "                  n_epochs=N_EPOCHS,\n",
    "                  n_pre_epochs=N_PRE_EPOCHS,\n",
    "                  verbose=VERBOSE,\n",
    "                  pretrain=PRETRAIN,\n",
    "                  X_val=x_power_val,\n",
    "                  y_val = mt_y_val.reshape(-1,1),\n",
    "                  best_model_name=\"{}_{}_networks_dcsfa.pt\".format(area,n_networks))\n",
    "        \n",
    "        torch.save(model,\"/work/mk423/Anxiety/singleFeaturedCSFAModels/\" + \"{}_{}_networks_dcsfa.pt\".format(area,n_networks))\n",
    "        \n",
    "        model._initialize(x_power.shape[1])\n",
    "        model.encoder.eval()\n",
    "        \n",
    "        validation_auc = model.score(x_power_val,mt_y_val.reshape(-1,1))\n",
    "        validation_recon = model.reconstruct(x_power_val)\n",
    "        validation_mse = np.mean((validation_recon - x_power_val)**2)\n",
    "        \n",
    "        val_auc_list.append(validation_auc)\n",
    "    \n",
    "    results_auc_dict[\"feature\"].append(area) \n",
    "    results_auc_dict[\"auc\"].append(np.max(val_auc_list))\n",
    "    results_auc_dict[\"n_networks\"].append(range(2,30)[np.argmax(val_auc_list)])\n",
    "    \n",
    "    print(\"{} , auc {}, n_net {}\".format(area,results_auc_dict[\"auc\"][-1],results_auc_dict[\"n_networks\"][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950278b6-8ff7-47be-a092-98364521ee21",
   "metadata": {},
   "source": [
    "## Check coherence feature predictiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57eea44d-1fc6-4dc0-a6b0-3b0d39d1b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amy-PrL_Cx , auc 0.5680900057506012, n_net 20\n",
      "Nac-VTA , auc 0.6106665034083896, n_net 29\n",
      "Cg_Cx-PrL_Cx , auc 0.7056598484697558, n_net 5\n",
      "Cg_Cx-IL_Cx , auc 0.7055565156057528, n_net 28\n",
      "IL_Cx-PrL_Cx , auc 0.7310479468965894, n_net 6\n"
     ]
    }
   ],
   "source": [
    "coh_features = [\"Amy-PrL_Cx\",\"Nac-VTA\",\"Cg_Cx-PrL_Cx\",\"Cg_Cx-IL_Cx\",\"IL_Cx-PrL_Cx\"]\n",
    "all_features = np.concatenate([anx_info_dict[\"powerFeatures\"],anx_info_dict[\"cohFeatures\"],anx_info_dict[\"gcFeatures\"]])\n",
    "\n",
    "for area in coh_features:\n",
    "    val_auc_list = []\n",
    "    freq_check = [area + ' ' + str(freq) for freq in range(56)]\n",
    "    feature_mask = np.array([feature in freq_check for feature in all_features])\n",
    "    \n",
    "    x_coh = mt_X_train[:,feature_mask==1]\n",
    "    x_coh_val = mt_X_val[:,feature_mask==1]\n",
    "    \n",
    "    for n_networks in range(2,30):\n",
    "    \n",
    "        model = DcsfaNmf(\n",
    "            n_components=n_networks,\n",
    "            n_intercepts = np.unique(mt_y_mouse_train).shape[0],\n",
    "            optim_name=\"SGD\",\n",
    "            sup_recon_weight=0.01,\n",
    "            sup_recon_type=\"All\",\n",
    "            save_folder = \"/work/mk423/Anxiety/singleFeaturedCSFAModels/\",\n",
    "            fixed_corr=[\"positive\"],\n",
    "        )\n",
    "\n",
    "        model.fit(x_power,\n",
    "                  mt_y_train.reshape(-1,1),\n",
    "                  intercept_mask=OneHotEncoder().fit_transform(mt_y_mouse_train.reshape(-1,1)).todense(),\n",
    "                  n_epochs=N_EPOCHS,\n",
    "                  n_pre_epochs=N_PRE_EPOCHS,\n",
    "                  verbose=VERBOSE,\n",
    "                  pretrain=PRETRAIN,\n",
    "                  X_val=x_power_val,\n",
    "                  y_val = mt_y_val.reshape(-1,1),\n",
    "                  best_model_name=\"{}_{}_networks_dcsfa.pt\".format(area,n_networks))\n",
    "\n",
    "        torch.save(model,\"/work/mk423/Anxiety/singleFeaturedCSFAModels/\" + \"{}_{}_networks_dcsfa.pt\".format(area,n_networks))\n",
    "\n",
    "        model._initialize(x_power.shape[1])\n",
    "        model.encoder.eval()\n",
    "\n",
    "        validation_auc = model.score(x_coh_val,mt_y_val.reshape(-1,1))\n",
    "        validation_recon = model.reconstruct(x_coh_val)\n",
    "        validation_mse = np.mean((validation_recon - x_coh_val)**2)\n",
    "\n",
    "        val_auc_list.append(validation_auc)\n",
    "\n",
    "    results_auc_dict[\"feature\"].append(area) \n",
    "    results_auc_dict[\"auc\"].append(np.max(val_auc_list))\n",
    "    results_auc_dict[\"n_networks\"].append(range(2,30)[np.argmax(val_auc_list)])\n",
    "    \n",
    "    print(\"{} , auc {}, n_net {}\".format(area,results_auc_dict[\"auc\"][-1],results_auc_dict[\"n_networks\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "260e41b4-76cd-404a-9bb9-5e0641c2db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results_auc_dict)\n",
    "df.to_csv(\"/hpc/home/mk423/Anxiety/MultiTaskWork/Validations/SingleFeatureAUCs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
